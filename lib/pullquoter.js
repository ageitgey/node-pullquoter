// Generated by CoffeeScript 2.0.0-beta7
void function () {
  var _, getTopSentences, math, memoize, natural, pullquoter, scoreSentences, sentenceSimilarity, splitIntoSentences, stopwords, tokenizeSentence;
  math = require('mathjs');
  natural = require('natural');
  stopwords = require('stopwords').english;
  memoize = require('memoizee');
  _ = require('lodash');
  module.exports = pullquoter = function (content, numberOfQuotes) {
    var sentences, sentenceScores;
    if (null == numberOfQuotes)
      numberOfQuotes = 1;
    sentences = splitIntoSentences(content);
    sentenceScores = scoreSentences(sentences);
    return getTopSentences(sentences, sentenceScores, numberOfQuotes);
  };
  splitIntoSentences = function (content) {
    var sentences;
    content = content.replace('\n', '. ');
    sentences = content.match(/(.+?[\.|\!|\?](?:\s|$))/g) || [];
    return _.map(sentences, function (sentence) {
      return sentence.trim();
    });
  };
  tokenizeSentence = function (s) {
    var tokenizer, tokens, words;
    tokenizer = new natural.WordPunctTokenizer;
    words = tokenizer.tokenize(s.toLowerCase());
    words = _.difference(words, stopwords);
    tokens = natural.PorterStemmer.tokenizeAndStem(words.join(' '));
    return tokens;
  };
  sentenceSimilarity = function (s1, s2) {
    var avgSentenceTokenLength, numberOfOverlappingTokens;
    if (s1.length + s2.length === 0)
      return 0;
    numberOfOverlappingTokens = _.intersection(s1, s2).length;
    avgSentenceTokenLength = (s1.length + s2.length) / 2;
    return numberOfOverlappingTokens / avgSentenceTokenLength;
  };
  scoreSentences = function (sentences) {
    var k, memoizedSimilarity, scores, tokenizedSentences, values;
    memoizedSimilarity = memoize(sentenceSimilarity);
    k = sentences.length;
    if (k <= 0)
      return [];
    if (k === 1)
      return [0];
    tokenizedSentences = _.map(sentences, tokenizeSentence);
    values = math.zeros(k, k).map(function (value, index, matrix) {
      var cache$, s1, s2;
      if (index[0] === index[1])
        return 0;
      s1 = tokenizedSentences[index[0]];
      s2 = tokenizedSentences[index[1]];
      if (s2 < s1) {
        cache$ = [
          s2,
          s1
        ];
        s1 = cache$[0];
        s2 = cache$[1];
        cache$;
      }
      return memoizedSimilarity(s1, s2);
    });
    scores = math.multiply(values, math.ones(k));
    return scores._data;
  };
  getTopSentences = function (sentences, sentenceScores, n) {
    var sentenceObjects;
    sentenceObjects = _.map(sentences, function (s, i) {
      return {
        sentence: s,
        score: sentenceScores[i],
        orderInText: i
      };
    });
    sentenceObjects = _.sortBy(sentenceObjects, function (sentence_score) {
      return -sentence_score.score;
    });
    if (sentenceObjects.length < n)
      n = sentenceObjects.length;
    sentenceObjects = sentenceObjects.slice(0, n);
    sentenceObjects = _.sortBy(sentenceObjects, function (sentence) {
      return sentence.orderInText;
    });
    return _.pluck(sentenceObjects, 'sentence');
  };
}.call(this);
